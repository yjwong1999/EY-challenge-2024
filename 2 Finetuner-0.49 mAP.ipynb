{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULE 2: Fine-tune on EY Challenge 2024 dataseet\n",
    "\n",
    "In this module, we will use the pretrained model from  Module 1, and fine-tune it using EY Challenge 2024 dataset. \n",
    "\n",
    "The pipeline for Module 2 is shown below:\n",
    "1. A **fine-grained dataset** is prepared. Specifically, we go through the post-event dataset, and find relevant images that are suitable for training. Notably, we keep in mind of the potential class imbalanced issue while collecting the relevant images. Then, we annotate the dataset.\n",
    "2. **Transfer Learning**: Use pretrained YOLOv8 (from Module 1) on the fine-grained dataset\n",
    "\n",
    "Note that without transfer learning using Module 1's YOLOv8, there is a high chance of overfitting on the actual test data provided by the EY Challenge 2024 dataset. You might get a better train mAP, but it does not actually reflect the mAP on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install YOLOv8\n",
    "!pip install ultralytics==8.0.196\n",
    "\n",
    "# Import required libraries\n",
    "from IPython import display\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip_folder(zip_filepath, dest_dir):\n",
    "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_dir)\n",
    "    print(f'The zip file {zip_filepath} has been extracted to the directory {dest_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zip file ./coarse-dataset.zip has been extracted to the directory ./coarse-dataset\n"
     ]
    }
   ],
   "source": [
    "# Coarse dataset\n",
    "zip_file = './coarse-dataset.zip'\n",
    "unzip_directory = './coarse-dataset'\n",
    "if not os.path.isdir(unzip_directory):\n",
    "    unzip_folder(zip_file,unzip_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zip file ./extra-fine-grained.zip has been extracted to the directory ./extra-fine-grained\n"
     ]
    }
   ],
   "source": [
    "# Extra-fine-grained dataset\n",
    "zip_file = './extra-fine-grained.zip'\n",
    "unzip_directory = './extra-fine-grained'\n",
    "if not os.path.isdir(unzip_directory):\n",
    "    unzip_folder(zip_file,unzip_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission dataset\n",
    "submission_zip = './challenge_1_submission_images.zip'\n",
    "submission_directory = './challenge_1_submission_images'\n",
    "if not os.path.isdir(submission_directory):\n",
    "    unzip_folder(submission_zip,submission_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/tham/Desktop/delete/EY/runs'\n",
      "[Errno 2] No such file or directory: '/home/tham/Desktop/delete/EY/submission.zip'\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "# if you are doing multiple experiments, you may need to delete previous runs\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('/home/tham/Desktop/delete/EY/runs')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    os.remove('/home/tham/Desktop/delete/EY/submission.zip')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"FmbGB9W7el5OsAuMapGm\")\n",
    "# project = rf.workspace(\"edge-4k8xw\").project(\"extra-fine-grained\")\n",
    "# version = project.version(2)\n",
    "# dataset = version.download(\"yolov8\")\n",
    "\n",
    "# display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.24 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 🚀 Python-3.8.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 Super, 7974MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/tham/Desktop/delete/EY/pretrained/detect/train/weights/best.pt, data=coarse-dataset/data.yaml, epochs=50, patience=50, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=1 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/tham/Desktop/delete/EY/coarse-dataset/train/labels... 417 \u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/tham/Desktop/delete/EY/coarse-dataset/train/images/tile_57_101_jpg.rf.10263dcc3eb78408479d4cf395c4d087.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/tham/Desktop/delete/EY/coarse-dataset/train/images/tile_57_101_jpg.rf.803a18bd00cf5c1c419655eebb0c7c4c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/tham/Desktop/delete/EY/coarse-dataset/train/images/tile_57_101_jpg.rf.8f08feb14e527498d8d2fafa26e2d4e0.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/tham/Desktop/delete/EY/coarse-dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tham/Desktop/delete/EY/coarse-dataset/valid/labels... 12 ima\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/tham/Desktop/delete/EY/coarse-dataset/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      1.65G      2.325      3.734      1.663         90        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.902     0.0682      0.335      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      1.69G      1.773      2.837      1.275         26        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.457      0.311      0.306       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      1.71G      1.658      2.175      1.236         23        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.223      0.478      0.266      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50      1.61G      1.591      1.917      1.224         19        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.265      0.462      0.355      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      1.68G      1.538      1.767      1.212         17        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.279      0.653      0.371      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      1.52G      1.502      1.709      1.208         14        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212       0.33      0.504      0.437      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      1.56G      1.506      1.648      1.204         26        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.371      0.531      0.405       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      1.66G       1.45      1.583      1.198          8        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.463      0.503      0.464      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      1.59G      1.451      1.516      1.195         15        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.495      0.419      0.451      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      1.64G      1.446      1.478      1.186         14        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.393      0.534      0.486      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      1.57G      1.432      1.487      1.183          5        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.561      0.445      0.504      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50       1.6G      1.385      1.421      1.179         18        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.513      0.498      0.508      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      1.58G      1.439      1.408       1.18         18        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.441      0.591      0.492      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      1.65G      1.405       1.41      1.172          8        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.463      0.477      0.485      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      1.58G       1.44      1.391      1.178         37        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.469      0.556      0.494      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      1.67G      1.372      1.353      1.155         13        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.594      0.492      0.516      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      1.61G       1.38      1.374      1.156          4        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.565      0.555      0.546      0.325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50      1.67G      1.405      1.353      1.148         49        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.515      0.479      0.499      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50      1.61G      1.352      1.333      1.155          6        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.504      0.599      0.536      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50      1.67G      1.361      1.278      1.137         32        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.491      0.541      0.495      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50      1.56G      1.371      1.316      1.177          6        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.426       0.59      0.514      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50      1.62G      1.391      1.272      1.158         15        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.558      0.479      0.528      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50      1.67G      1.339      1.294      1.131          3        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212       0.43      0.549      0.501        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50      1.62G      1.318      1.244      1.122         52        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.427       0.55      0.462      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50      1.64G      1.311       1.22      1.125         26        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.486      0.527      0.524      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50      1.72G      1.353       1.21      1.143         12        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.446      0.608      0.502      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50       1.6G      1.324      1.173      1.131          8        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.528      0.512      0.531      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50      1.68G      1.323      1.199      1.133         15        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.426      0.577      0.491      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50       1.6G      1.307      1.179      1.117         14        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.544      0.471      0.508      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50      1.57G      1.326      1.153      1.127         15        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.482      0.523      0.507      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50      1.46G      1.333      1.204      1.119         22        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.539       0.51      0.541      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50      1.61G      1.322      1.161      1.138         14        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.544      0.512      0.504      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50      1.74G      1.264      1.124      1.094         10        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.481      0.561      0.491        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50      1.47G      1.304      1.122      1.114         49        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.535      0.524       0.54       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50      1.71G      1.289      1.126      1.107         36        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212       0.49      0.561      0.518      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50      1.64G      1.291      1.136      1.122          8        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.475      0.522      0.487      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50      1.63G      1.267      1.098      1.107         14        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.437      0.632      0.514      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50      1.61G      1.287      1.079      1.117         22        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.439      0.585      0.515      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50      1.68G      1.283      1.103      1.118         22        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.552      0.456      0.521      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50      1.61G      1.278      1.176       1.12          5        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212       0.54      0.468      0.506      0.297\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50      1.57G      1.253      1.113      1.103         12        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.513      0.507       0.52      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50      1.46G      1.233      1.067      1.106         21        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.511      0.523      0.489      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50      1.42G      1.231      1.038      1.109         10        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.498      0.508      0.507      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50      1.46G        1.2      1.019      1.087          7        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.557      0.463       0.51      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50      1.48G      1.205      1.004      1.088         26        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.492      0.449      0.479      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50      1.54G      1.199     0.9972      1.094          5        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.545       0.47      0.499      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50      1.53G      1.185     0.9776      1.083          6        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.511      0.534      0.526      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50      1.54G      1.194     0.9674      1.085         25        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212       0.49      0.496      0.506      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50      1.51G      1.246     0.9863      1.112          7        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.428      0.554      0.501      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50      1.53G      1.218     0.9787      1.094         22        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.434      0.551      0.507      0.309\n",
      "\n",
      "50 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.196 🚀 Python-3.8.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 Super, 7974MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         12        212      0.506      0.599      0.537      0.331\n",
      "                     0         12        132      0.667      0.826      0.812      0.489\n",
      "                     1         12         11       0.57      0.605      0.579      0.399\n",
      "                     2         12         60      0.368      0.633      0.406      0.223\n",
      "                     3         12          9      0.418      0.333      0.351      0.212\n",
      "Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2, 3])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f291c026c70>\n",
       "fitness: 0.3513725514503218\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.4892,      0.3992,     0.22253,     0.21205])\n",
       "names: {0: '0', 1: '1', 2: '2', 3: '3'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.5059302947682462, 'metrics/recall(B)': 0.5993382587132587, 'metrics/mAP50(B)': 0.5370082715449616, 'metrics/mAP50-95(B)': 0.3307463603286952, 'fitness': 0.3513725514503218}\n",
       "save_dir: PosixPath('runs/detect/train')\n",
       "speed: {'preprocess': 0.110169251759847, 'inference': 0.962217648824056, 'loss': 0.0010530153910319011, 'postprocess': 1.1388659477233887}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# yaml file of the training dataset\n",
    "yaml_file = \"coarse-dataset/data.yaml\"\n",
    "\n",
    "# use COCO pretrained YOLOv8 models from Module 1 for transfer learning\n",
    "model = YOLO(\"/home/tham/Desktop/delete/EY/pretrained/detect/train/weights/best.pt\")\n",
    "model.train(data=yaml_file, epochs=50, imgsz=512, plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "import os\n",
    "os.rename('runs', 'runs (coarse)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.24 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 🚀 Python-3.8.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 Super, 7974MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/tham/Desktop/delete/EY/runs (coarse)/detect/train/weights/best.pt, data=extra-fine-grained/data.yaml, epochs=10, patience=50, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/tham/Desktop/delete/EY/extra-fine-grained/train/labels... \u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/tham/Desktop/delete/EY/extra-fine-grained/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tham/Desktop/delete/EY/extra-fine-grained/valid/labels... 10\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/tham/Desktop/delete/EY/extra-fine-grained/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      1.47G      2.277       1.98      1.796         55        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.277      0.463      0.292       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10       1.5G      1.942      1.745      1.558        102        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.309      0.488      0.338       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      1.46G        1.6      1.717      1.369         62        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.364       0.35      0.331      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      1.52G      1.494      1.707      1.374         84        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.366       0.37       0.33      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      1.52G      1.448      1.712      1.321         38        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.358      0.378      0.349      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      1.52G      1.393      1.534      1.294         47        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.289      0.526      0.352      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      1.49G      1.414      1.583      1.309         47        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.308      0.609      0.386      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      1.48G      1.353      1.511      1.246         76        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.286      0.543      0.338       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10       1.5G      1.354      1.495      1.237         46        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.276       0.49      0.332      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10       1.5G      1.306       1.49      1.234         61        512: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.269      0.488      0.328      0.185\n",
      "\n",
      "10 epochs completed in 0.003 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.196 🚀 Python-3.8.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 Super, 7974MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         10        210      0.309       0.61      0.385      0.202\n",
      "                     0         10        150      0.513       0.88      0.706      0.386\n",
      "                     1         10         23      0.164       0.13     0.0721     0.0455\n",
      "                     2         10         34      0.273      0.765      0.326      0.179\n",
      "                     3         10          3      0.285      0.664      0.437      0.197\n",
      "Speed: 0.2ms preprocess, 1.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2, 3])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f29444a6160>\n",
       "fitness: 0.2200792007977212\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.3858,    0.045482,     0.17868,     0.19688])\n",
       "names: {0: '0', 1: '1', 2: '2', 3: '3'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.3085945346819713, 'metrics/recall(B)': 0.6096801844318783, 'metrics/mAP50(B)': 0.38537524197395795, 'metrics/mAP50-95(B)': 0.20171297400036153, 'fitness': 0.2200792007977212}\n",
       "save_dir: PosixPath('runs/detect/train')\n",
       "speed: {'preprocess': 0.1718282699584961, 'inference': 1.0261774063110352, 'loss': 0.001049041748046875, 'postprocess': 1.3030767440795898}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# yaml file of the training dataset\n",
    "# yaml_file = f\"{dataset.location}/data.yaml\"\n",
    "yaml_file = \"extra-fine-grained/data.yaml\"\n",
    "\n",
    "# use COCO pretrained YOLOv8 models from Module 1 for transfer learning\n",
    "model = YOLO(\"/home/tham/Desktop/delete/EY/runs (coarse)/detect/train/weights/best.pt\")\n",
    "model.train(data=yaml_file, epochs=10, imgsz=512, plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Results and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f'runs/detect/train/confusion_matrix.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=f'runs/detect/train/results.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=f'runs/detect/train/val_batch0_pred.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the metrics provided\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'runs/detect/train/results.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = df['                  epoch']\n",
    "mAP50_B = df['       metrics/mAP50(B)']\n",
    "mAP50_95_B = df['    metrics/mAP50-95(B)']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.plot(epochs, mAP50_B, label='mAP50(B)')\n",
    "ax.plot(epochs, mAP50_95_B, label='    metrics/mAP50-95(B)')\n",
    "ax.set_ylabel('mAP')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n",
    "fig.suptitle('mAP50(B) and mAP50-95(B) vs Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip_folder(zip_filepath, dest_dir):\n",
    "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_dir)\n",
    "    print(f'The zip file {zip_filepath} has been extracted to the directory {dest_dir}')\n",
    "\n",
    "\n",
    "\n",
    "submission_zip = './challenge_1_submission_images.zip'\n",
    "submission_directory = './challenge_1_submission_images'\n",
    "if not os.path.isdir(submission_directory):\n",
    "    unzip_folder(submission_zip,submission_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "model = YOLO('runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_006.jpg: 512x512 32 0s, 1 1, 6 2s, 5.3ms\n",
      "Speed: 0.6ms preprocess, 5.3ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "1 label saved to runs/detect/predict/labels\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "challenge_1_submission_images/Submission data/Validation_Post_Event_006.jpg\n",
      "Making a prediction on  Validation_Post_Event_006.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_012.jpg\n",
      "Making a prediction on  Validation_Post_Event_012.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_012.jpg: 512x512 23 0s, 2 1s, 5 2s, 9.8ms\n",
      "Speed: 0.7ms preprocess, 9.8ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "2 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_005.jpg: 512x512 32 0s, 2 2s, 8.5ms\n",
      "Speed: 0.8ms preprocess, 8.5ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "3 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_002.jpg: 512x512 6 0s, 4 2s, 1 3, 8.3ms\n",
      "Speed: 0.7ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "4 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_004.jpg: 512x512 12 0s, 2 2s, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "5 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_007.jpg: 512x512 28 0s, 13 2s, 1 3, 6.5ms\n",
      "Speed: 0.7ms preprocess, 6.5ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "6 labels saved to runs/detect/predict/labels\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_005.jpg\n",
      "Making a prediction on  Validation_Post_Event_005.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_002.jpg\n",
      "Making a prediction on  Validation_Post_Event_002.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_004.jpg\n",
      "Making a prediction on  Validation_Post_Event_004.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_007.jpg\n",
      "Making a prediction on  Validation_Post_Event_007.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_009.jpg\n",
      "Making a prediction on  Validation_Post_Event_009.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_009.jpg: 512x512 18 0s, 1 1, 3 2s, 3 3s, 6.8ms\n",
      "Speed: 0.8ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "7 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_010.jpg: 512x512 11 0s, 3 1s, 2 2s, 2 3s, 7.2ms\n",
      "Speed: 0.7ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "8 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_011.jpg: 512x512 7 0s, 2 1s, 2 2s, 6.8ms\n",
      "Speed: 0.7ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "9 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_003.jpg: 512x512 12 0s, 4 2s, 6.2ms\n",
      "Speed: 0.6ms preprocess, 6.2ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "10 labels saved to runs/detect/predict/labels\n",
      "\n",
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_008.jpg: 512x512 12 0s, 4 2s, 6.1ms\n",
      "Speed: 0.8ms preprocess, 6.1ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "11 labels saved to runs/detect/predict/labels\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_010.jpg\n",
      "Making a prediction on  Validation_Post_Event_010.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_011.jpg\n",
      "Making a prediction on  Validation_Post_Event_011.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_003.jpg\n",
      "Making a prediction on  Validation_Post_Event_003.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_008.jpg\n",
      "Making a prediction on  Validation_Post_Event_008.jpg\n",
      "Output files generated successfully.\n",
      "challenge_1_submission_images/Submission data/Validation_Post_Event_001.jpg\n",
      "Making a prediction on  Validation_Post_Event_001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/tham/Desktop/delete/EY/challenge_1_submission_images/Submission data/Validation_Post_Event_001.jpg: 512x512 23 0s, 14 2s, 6.2ms\n",
      "Speed: 0.7ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "12 labels saved to runs/detect/predict/labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Decoding according to the .yaml file class names order\n",
    "decoding_of_predictions ={0: 'undamagedresidentialbuilding', 1: 'undamagedcommercialbuilding', 2: 'damagedresidentialbuilding', 3: 'damagedcommercialbuilding'}\n",
    "\n",
    "directory = 'challenge_1_submission_images/Validation_Data_JPEG'\n",
    "directory = 'challenge_1_submission_images/Submission data'\n",
    "# Directory to store outputs\n",
    "results_directory = 'Validation_Data_Results'\n",
    "\n",
    "# Create submission directory if it doesn't exist\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the current object is a file and ends with .jpeg\n",
    "    if os.path.isfile(os.path.join(directory, filename)) and filename.lower().endswith('.jpg'):\n",
    "        # Perform operations on the file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        print(file_path)\n",
    "        print(\"Making a prediction on \", filename)\n",
    "        results = model.predict(file_path, save=True, iou=0.5, save_txt=True, conf=0.25)\n",
    "        \n",
    "        for r in results:\n",
    "            conf_list = r.boxes.conf.cpu().numpy().tolist()\n",
    "            clss_list = r.boxes.cls.cpu().numpy().tolist()\n",
    "            original_list = clss_list\n",
    "            updated_list = []\n",
    "            for element in original_list:\n",
    "                 updated_list.append(decoding_of_predictions[int(element)])\n",
    "\n",
    "        bounding_boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        confidences = conf_list\n",
    "        class_names = updated_list\n",
    "\n",
    "        # Check if bounding boxes, confidences and class names match\n",
    "        if len(bounding_boxes) != len(confidences) or len(bounding_boxes) != len(class_names):\n",
    "            print(\"Error: Number of bounding boxes, confidences, and class names should be the same.\")\n",
    "            continue\n",
    "        text_file_name = os.path.splitext(filename)[0]\n",
    "        # Creating a new .txt file for each image in the submission_directory\n",
    "        with open(os.path.join(results_directory, f\"{text_file_name}.txt\"), \"w\") as file:\n",
    "            for i in range(len(bounding_boxes)):\n",
    "                # Get coordinates of each bounding box\n",
    "                left, top, right, bottom = bounding_boxes[i]\n",
    "                # Write content to file in desired format\n",
    "                file.write(f\"{class_names[i]} {confidences[i]} {left} {top} {right} {bottom}\\n\")\n",
    "        print(\"Output files generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Validation_Data_Results has been successfully zipped into submission.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Define your source directory and the destination where the zip file will be created\n",
    "source_dir = results_directory\n",
    "destination_zip = 'submission'\n",
    "\n",
    "# Create a zip file from the directory\n",
    "shutil.make_archive(destination_zip, 'zip', source_dir)\n",
    "\n",
    "print(f\"Directory {source_dir} has been successfully zipped into {destination_zip}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qCvb0-XuvYJ0",
    "St5XGxy6vhY7",
    "VcOfSMsXvpkE"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
