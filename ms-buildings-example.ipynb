{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64bd13a2-e1bb-43cd-846c-410346c55d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Microsoft Building Footprints\n",
    "\n",
    "Bing Maps is releasing open building footprints around the world. The building footprints are detected using Bing Maps imagery between 2014 and 2021 including Maxar and Airbus imagery. The data is freely available for download and use under ODbL.\n",
    "\n",
    "Our aim is to use this dataset to pretrain a robust building detection model from satelite image, which can then be fine-tuned for specific use-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ed8e4-2c53-4650-834f-4c386c3fcd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# https://github.com/opengeos/leafmap/blob/e35e0a75a125614244e5913755c50ec4f307bcab/docs/notebooks/74_map_tiles_to_geotiff.ipynb#L7\n",
    "# require reload after installation\n",
    "%pip install -U leafmap\n",
    "clear_output()\n",
    "\n",
    "# restart kernel\n",
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05217579-1f22-4c5c-a649-6fcbd2cc2773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import planetary_computer\n",
    "import pystac_client\n",
    "import dask.dataframe\n",
    "import dask_geopandas\n",
    "import dask.distributed\n",
    "import deltalake\n",
    "import shapely.geometry\n",
    "import contextily\n",
    "import mercantile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceab670-3781-4ca6-9c10-0177f9ac450d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data access\n",
    "\n",
    "The datasets hosted by the Planetary Computer are available from [Azure Blob Storage](https://docs.microsoft.com/en-us/azure/storage/blobs/). We'll use [pystac-client](https://pystac-client.readthedocs.io/) to search the Planetary Computer's [STAC API](https://planetarycomputer.microsoft.com/api/stac/v1/docs) to get a link to the assets. We'll specify a `modifier` so that we can access the data stored in the Planetary Computer's private Blob Storage Containers. See [Reading from the STAC API](https://planetarycomputer.microsoft.com/docs/quickstarts/reading-stac/) and [Using tokens for data access](https://planetarycomputer.microsoft.com/docs/concepts/sas/) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dfc9a9-c787-41c3-aaa8-95787bed362c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "collection = catalog.get_collection(\"ms-buildings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c937a5-8ceb-46e8-9b27-b154184236fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using Delta Table Files\n",
    "\n",
    "The assets are a set of [geoparquet](https://geoparquet.org/) files grouped by a processing date. Newer files (since April 25th, 2023) are stored in [Delta Format](https://docs.delta.io/latest/delta-intro.html). This is a layer on top of parquet files offering scalable metadata handling, which is useful for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aace14f8-5a33-42e1-9651-44e0f1826546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asset = collection.assets[\"delta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f7f60-1761-4d2e-8e7f-938aad628b87",
   "metadata": {
    "tags": []
   },
   "source": [
    "This Delta Table is partitioned by `RegionName` and `quadkey`. Each `(RegionName, quadkey)` pair will contain one or more parquet files (depending on how dense that particular quadkey) is. The quadkeys are at level 9 of the [Bing Maps Tile System](https://learn.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d30272-1914-4c57-b0d6-c93a9db59c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_options = {\n",
    "    \"account_name\": asset.extra_fields[\"table:storage_options\"][\"account_name\"],\n",
    "    \"sas_token\": asset.extra_fields[\"table:storage_options\"][\"credential\"],\n",
    "}\n",
    "table = deltalake.DeltaTable(asset.href, storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a247424-0e04-460f-8b77-d333c715b217",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### (Optional) Examples of using the Delta Table\n",
    "\n",
    "You can load all the files for a given `RegionName` with a query like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c0903-a71c-4ca8-8500-3bf9f7edb1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_uris = table.file_uris([(\"RegionName\", \"=\", \"VaticanCity\")])\n",
    "\n",
    "# df = dask_geopandas.read_parquet(file_uris, storage_options=storage_options)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c235ec0-68f4-4621-875f-9c81a4c0ddf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ax = df.compute().plot(figsize=(12, 12), color=\"yellow\")\n",
    "# contextily.add_basemap(\n",
    "#     ax,\n",
    "#     source=contextily.providers.Esri.WorldGrayCanvas,\n",
    "#     crs=df.crs.to_string(),\n",
    "#     zoom=16,\n",
    "# )\n",
    "# ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421eda4c-1112-4553-9df2-136a727820f7",
   "metadata": {},
   "source": [
    "This partitioning, and the Delta Table format, let you quickly query the subset of files that match your area of interest.\n",
    "\n",
    "For example, we can visualize the footprints for a small region outside the town of UeckermÃ¼nde in Northeast Germany defined by this bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5908697-1f05-4c17-8a1b-298fcd54455e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# area_of_interest = shapely.geometry.box(14.11, 53.73, 14.13, 53.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2dfa3-7476-4fb5-840b-3c4f92161b52",
   "metadata": {},
   "source": [
    "You will need to translate your area of interest to a set of intersecting quadkeys, which can be done with [mercantile](https://mercantile.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e8ca5-4327-47dc-919b-c8ff99faa43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# quadkeys = [\n",
    "#     int(mercantile.quadkey(tile))\n",
    "#     for tile in mercantile.tiles(*area_of_interest.bounds, zooms=9)\n",
    "# ]\n",
    "# quadkeys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e23ab-b8bb-4609-b316-247ec5fbcf99",
   "metadata": {},
   "source": [
    "Now we can provide those quadkeys as a partition filter to get the set of matching URIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9870f3-4baf-4aa2-9921-a076e4b9f797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uris = table.file_uris([(\"RegionName\", \"=\", \"Germany\"), (\"quadkey\", \"in\", quadkeys)])\n",
    "# uris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65796c3-63fd-44b8-823f-f858703821bc",
   "metadata": {},
   "source": [
    "And quickly load them into, for example, a dask-geopandas `GeoDataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8db22-8e66-4274-bbac-afbcda256899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = dask_geopandas.read_parquet(uris, storage_options=storage_options)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e3dbb-4196-4ba9-86c3-9d0a1496a3bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utilites function to Extract Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5edf97c-ff54-4c3f-aa4e-094c798bf411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import leafmap\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image # ImageDraw\n",
    "# from itertools import chain\n",
    "from IPython.display import clear_output\n",
    "# cv2 cannot be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff23976-f8d6-4431-995a-11456f0c2dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# get bounding box of buildings in the city\n",
    "#------------------------------------------------\n",
    "def getBuildingBbox(city):\n",
    "    file_uris = table.file_uris([(\"RegionName\", \"=\", city)])\n",
    "    # file_uris = table.file_uris([(\"quadkey\", \"=\", city)])\n",
    "    df = dask_geopandas.read_parquet(file_uris, storage_options=storage_options)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#------------------------------------------------\n",
    "# get the bounding box of the entire city\n",
    "#------------------------------------------------\n",
    "def getRegionBbox(df):\n",
    "    # get region bbox\n",
    "    bounded_df = df.compute().bounds \n",
    "    _, _, maxx, maxy = bounded_df.max()\n",
    "    minx, miny, _, _ = bounded_df.min()\n",
    "    region_bbox = [minx, miny, maxx, maxy]\n",
    "\n",
    "    return region_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359e7afe-75d2-452d-94d0-418131e20dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# crop the region into tiles\n",
    "#------------------------------------------------\n",
    "def cropRegion(region_bbox, step):\n",
    "    # region bounding box\n",
    "    minx, miny, maxx, maxy = region_bbox\n",
    "    \n",
    "    # store all bbox in each tile\n",
    "    region_bbox_list = []\n",
    "    \n",
    "    # handle large image situation, crop into tiles\n",
    "    if (maxx - minx) > step or (maxy - miny) > step:\n",
    "        new_minx, new_miny = minx, miny\n",
    "\n",
    "        num_x_tiles = int((maxx - minx)//step + 1)\n",
    "        num_y_tiles = int((maxy - miny)//step + 1)\n",
    "        \n",
    "        print(f'Number of x tiles: {num_x_tiles}')\n",
    "        print(f'Number of y tiles: {num_y_tiles}')\n",
    "        \n",
    "        print(f'\\nTotal number of tiles: {num_x_tiles*num_y_tiles}')\n",
    "        for i in range(num_y_tiles):\n",
    "            for j in range(num_x_tiles):\n",
    "                new_maxx, new_maxy = new_minx + step, new_miny + step\n",
    "                \n",
    "                region_bbox = [new_minx, new_miny, new_maxx, new_maxy]\n",
    "                region_bbox_list.append(region_bbox)\n",
    "                \n",
    "                new_minx = new_maxx\n",
    "\n",
    "            new_minx = minx\n",
    "            new_miny = new_maxy\n",
    "    \n",
    "    # if small image, then treat the entire image as one tile\n",
    "    else:\n",
    "        region_bbox_list.append(region_bbox)\n",
    "    \n",
    "    return region_bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df285a55-a832-4008-b74b-0c43f35cd6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# An assumption that each building exist only within one of the tiles\n",
    "# to save computational power & time\n",
    "#------------------------------------------------\n",
    "def createList(row, num_x_tiles, step):\n",
    "    return int(row['left_tile']+row['top_tile']*num_x_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d193261-f059-4b0d-b679-7b9feb19b2b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "\n",
    "#------------------------------------------------\n",
    "def labelTileRegion(region_bbox, bounded_df, step):\n",
    "    minx, miny, maxx, maxy = region_bbox\n",
    "    \n",
    "    bounded_df['left_tile'] = (bounded_df['minx'] - minx)//step\n",
    "    bounded_df['right_tile'] = (bounded_df['maxx'] - minx)//step + 1\n",
    "    bounded_df['top_tile'] = (bounded_df['miny'] - miny)//step\n",
    "    bounded_df['bottom_tile'] = (bounded_df['maxy'] - miny)//step + 1\n",
    "    \n",
    "    # bounded_df['left_tile'] = bounded_df['left_tile'].astype(int)\n",
    "    # bounded_df['right_tile'] = bounded_df['right_tile'].astype(int)\n",
    "    # bounded_df['top_tile'] = bounded_df['top_tile'].astype(int)\n",
    "    # bounded_df['bottom_tile'] = bounded_df['bottom_tile'].astype(int)\n",
    "    \n",
    "    num_x_tiles = int((maxx - minx)//step + 1)\n",
    "    num_y_tiles = int((maxy - miny)//step + 1)\n",
    "    \n",
    "    bounded_df['Tile'] = bounded_df.apply(lambda row: createList(row, num_x_tiles, step), axis=1)\n",
    "    \n",
    "    return bounded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6151b5-d0b8-4738-990c-c4c97fe7c816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# Filtering: we only want buildings which are inside the region (city)\n",
    "#------------------------------------------------\n",
    "def filterDf(region_bbox, bounded_df):\n",
    "    minx, miny, maxx, maxy = region_bbox\n",
    "    \n",
    "    new_bounded_df = bounded_df.copy()\n",
    "    \n",
    "    new_bounded_df['minx'] = new_bounded_df['minx'].apply(lambda x: minx if x < minx else x)\n",
    "    new_bounded_df['minx'] = new_bounded_df['minx'].apply(lambda x: np.nan if x > maxx else x)\n",
    "    new_bounded_df['maxx'] = new_bounded_df['maxx'].apply(lambda x: maxx if x > maxx else x)\n",
    "    new_bounded_df['maxx'] = new_bounded_df['maxx'].apply(lambda x: np.nan if x < minx else x)\n",
    "    \n",
    "    new_bounded_df['miny'] = new_bounded_df['miny'].apply(lambda x: miny if x < miny else x)\n",
    "    new_bounded_df['miny'] = new_bounded_df['miny'].apply(lambda x: np.nan if x > maxy else x)\n",
    "    new_bounded_df['maxy'] = new_bounded_df['maxy'].apply(lambda x: maxy if x > maxy else x)\n",
    "    new_bounded_df['maxy'] = new_bounded_df['maxy'].apply(lambda x: np.nan if x < miny else x)\n",
    "    \n",
    "    new_bounded_df = new_bounded_df.dropna(how='any')\n",
    "    \n",
    "    return new_bounded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95929cb-2269-4dc1-89e6-15afa3d6c25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# normalize the bounding box into YOLO annotation format:\n",
    "# class, x center, y center, width, height\n",
    "#------------------------------------------------\n",
    "def normaliseBbox(region_bbox, region_bbox_list, df, step):\n",
    "    tile_bbox_list = []\n",
    "    filtered_region_bbox_list = []\n",
    "    bounded_df = df.bounds\n",
    "    bounded_df = labelTileRegion(region_bbox, bounded_df, step)\n",
    "    \n",
    "    # region_list = set(chain.from_iterable(row['Tile'] for _, row in bounded_df.iterrows()))\n",
    "    region_list = set(bounded_df['Tile'].compute().to_list())\n",
    "    \n",
    "    # Testing purpose\n",
    "    # region_list = [1242]\n",
    "    # print(bounded_df.head(5))\n",
    "    # print(region_bbox_list[region_list[0]])\n",
    "    \n",
    "    print(f'Number of region tiles after filtering: {len(region_list)}')\n",
    "    print('\\nGenerating tiles...')\n",
    "    region_list = list(region_list)[290:300] # change here\n",
    "    for count, region in enumerate(region_list):\n",
    "        count += 290 # change here\n",
    "        print(f'\\n~ Tile {count}')\n",
    "        region_bbox = region_bbox_list[region]\n",
    "        new_bounded_df = filterDf(region_bbox, bounded_df)\n",
    "        cropped_minx, cropped_miny, cropped_maxx, cropped_maxy = region_bbox\n",
    "\n",
    "        # normalise bounding box\n",
    "        # get building world map bbox\n",
    "        building_minx = new_bounded_df['minx']\n",
    "        building_miny = new_bounded_df['miny']\n",
    "        building_maxx = new_bounded_df['maxx']\n",
    "        building_maxy = new_bounded_df['maxy']\n",
    "\n",
    "        # normalized building bbox to the region (0 to 1 range)\n",
    "        new_bounded_df['building_minx'] = (building_minx - cropped_minx) / (cropped_maxx - cropped_minx)\n",
    "        new_bounded_df['building_miny'] = (building_miny - cropped_miny) / (cropped_maxy - cropped_miny)\n",
    "        new_bounded_df['building_maxx'] = (building_maxx - cropped_minx) / (cropped_maxx - cropped_minx)\n",
    "        new_bounded_df['building_maxy'] = (building_maxy - cropped_miny) / (cropped_maxy - cropped_miny) \n",
    "\n",
    "        # flip y axis, due to some reason\n",
    "        new_bounded_df['building_miny'] = 1 - new_bounded_df['building_miny']\n",
    "        new_bounded_df['building_maxy'] = 1 - new_bounded_df['building_maxy']\n",
    "        new_bounded_df['building_miny'], new_bounded_df['building_maxy'] = new_bounded_df['building_maxy'], new_bounded_df['building_miny']\n",
    "\n",
    "        # get bbox\n",
    "        new_bounded_df['class'] = 0\n",
    "        new_bounded_df['x'] = (new_bounded_df['building_maxx'] + new_bounded_df['building_minx']) / 2\n",
    "        new_bounded_df['y'] = (new_bounded_df['building_maxy'] + new_bounded_df['building_miny']) / 2\n",
    "        new_bounded_df['w'] = new_bounded_df['building_maxx'] - new_bounded_df['building_minx']\n",
    "        new_bounded_df['h'] = new_bounded_df['building_maxy'] - new_bounded_df['building_miny']\n",
    "\n",
    "        new_bounded_df = new_bounded_df[(new_bounded_df['w'] != 0.0) & (new_bounded_df['h'] != 0.0)]\n",
    "\n",
    "        if len(new_bounded_df.index) != 0:\n",
    "            new_df = new_bounded_df[['class', 'x', 'y', 'w', 'h']]\n",
    "            tile_bbox_list.append(new_df)\n",
    "            filtered_region_bbox_list.append(region_bbox)\n",
    "            \n",
    "            # saving while filtering\n",
    "            saveBbox([new_df], city, count)\n",
    "            saveRegionTif(city, [region_bbox], count, zoom=20)\n",
    "            \n",
    "            clear_output()\n",
    "            \n",
    "    print('Done filtering and normalising.')\n",
    "    \n",
    "    return tile_bbox_list, filtered_region_bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a058d171-b1b0-4e34-885c-cde7a4e4d635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# save bounding box into anntotaion txt files\n",
    "#------------------------------------------------\n",
    "def saveBbox(tile_bbox_list, city, count):\n",
    "    output_directory = './region_labels'\n",
    "    output_city_directory = f'./region_labels/{city}'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    if not os.path.exists(output_city_directory):\n",
    "        os.makedirs(output_city_directory)\n",
    "    \n",
    "    if not isinstance(tile_bbox_list, list):\n",
    "        tile_bbox_list = [tile_bbox_list]\n",
    "    \n",
    "    print('\\nGenerating labels...')\n",
    "    for building_df in tile_bbox_list:\n",
    "        file_name = f'{city}_{str(count).zfill(5)}.txt'\n",
    "\n",
    "        with open(f'./region_labels/{city}/{file_name}', 'w') as f:\n",
    "            df_string = building_df.compute().to_string(header=False, index=False)\n",
    "            f.write(df_string)\n",
    "\n",
    "    print(f\"{city}'s label saved.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8dfbec-9099-49fd-85be-367af2807f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# save region tif\n",
    "#------------------------------------------------\n",
    "def saveRegionTif(city, region_bbox_list, count, zoom=20):\n",
    "    output_directory = './region_tif'\n",
    "    output_city_directory = f'./region_tif/{city}'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    if not os.path.exists(output_city_directory):\n",
    "        os.makedirs(output_city_directory)\n",
    "    \n",
    "    # get tif image\n",
    "    print(f'A total of {len(region_bbox_list)} images will be saved.')\n",
    "    for region_bbox in region_bbox_list:\n",
    "        minx, miny, maxx, maxy = region_bbox\n",
    "    \n",
    "        output_path = output_city_directory + f'/{city}_{str(count).zfill(5)}.tif'\n",
    "        leafmap.map_tiles_to_geotiff(output_path, region_bbox, zoom=zoom, source='SATELLITE')\n",
    "    \n",
    "    print(f\"{city}'s tif file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec550d9-88a3-4599-93dc-a16755bfbceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "# convert tiff to jpg\n",
    "#------------------------------------------------\n",
    "def convert_tiff_to_jpeg(input_dir, output_dir):\n",
    "    # check if output_dir exists, if not create it\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        # check if file is an image (ends with .tif)\n",
    "        if filename.endswith('.tif'):\n",
    "            img = Image.open(os.path.join(input_dir, filename))\n",
    "\n",
    "            # check if image is RGB mode, if not convert it\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            # create new filename, replace .tif with .jpg\n",
    "            output_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "\n",
    "            # save the image in JPEG format\n",
    "            img.save(os.path.join(output_dir, output_filename), 'JPEG')\n",
    "            \n",
    "    print(\"Conversion from TIFF to JPEG completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f2234b-25cd-4313-a6ce-5d8f4feea1f0",
   "metadata": {},
   "source": [
    "### Start extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9abb6e-9973-4b91-9ae3-a1442d7af0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done filtering and normalising.\n",
      "Converting TIFF to JPEG...\n",
      "Conversion from TIFF to JPEG completed.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------\n",
    "# main function\n",
    "#------------------------------------------------\n",
    "for city in ['PuertoRico']:\n",
    "    # which city\n",
    "    print(f'=== {city} ===')\n",
    "    \n",
    "    # get all bounding box of buildings in this city\n",
    "    df = getBuildingBbox(city)\n",
    "    \n",
    "    # get the bounding box of the entire city itself\n",
    "    region_bbox = getRegionBbox(df)\n",
    "    print(f'Region Bbox: {region_bbox}')\n",
    "    \n",
    "    step = 0.01\n",
    "    region_bbox_list = cropRegion(region_bbox, step)\n",
    "\n",
    "    tile_bbox_list, filtered_region_bbox_list = normaliseBbox(region_bbox, region_bbox_list, df, step)\n",
    "    \n",
    "#     if len(tile_bbox_list) != 0:\n",
    "#         saveBbox(tile_bbox_list, city)\n",
    "\n",
    "#         saveRegionTif(city, filtered_region_bbox_list, zoom=20)\n",
    "#         convert_tiff_to_jpeg(f'./region_tif/{city}/', f'./region_jpeg/{city}/')\n",
    "\n",
    "    print('Converting TIFF to JPEG...')\n",
    "    convert_tiff_to_jpeg(f'./region_tif/{city}/', f'./region_jpeg/{city}/')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e947fe-a170-4ae8-9f0f-e39300deb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip file for downloading\n",
    "# !zip -r ./region_tif.zip ./region_tif\n",
    "!zip -r ./region_jpeg.zip ./region_jpeg\n",
    "!zip -r ./region_labels.zip ./region_labels/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf995f9-2289-4f80-925e-44f464d65f0a",
   "metadata": {},
   "source": [
    "**Afternote**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28377d37-b75d-4912-bd71-a6acdcb13c4b",
   "metadata": {},
   "source": [
    "Upload all the images and labels to Roboflow for converting to XML format.</br>\n",
    "Run colab GenerateTile.ipynb file to generate tiles for each image.</br>\n",
    "Upload back to Roboflow for convertion to YOLO format and model training.</br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
